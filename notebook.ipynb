{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv fastai_env\n",
    "!fastai_env\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install pillow\n",
    "!pip install fastai\n",
    "!pip install scikit-learn\n",
    "!pip install mss\n",
    "!pip install pynput\n",
    "!pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Computer vision and image processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch and related modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# FastAI for deep learning\n",
    "from fastai.vision.all import *\n",
    "\n",
    "# Scikit-learn for model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Screen capture and keyboard control\n",
    "import mss\n",
    "from pynput import keyboard as key\n",
    "import keyboard  # Another keyboard control library, different from pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store data\n",
    "data_dir = \"trackmania_data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Create directories for labels\n",
    "for label in ['0', '1', '2', '3']:  # 0: straight (w), 1: left (a), 2: right (d), 3: backward\n",
    "    label_dir = os.path.join(data_dir, label)\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "\n",
    "# Variable to store the pressed key\n",
    "key_pressed = None\n",
    "\n",
    "# Function to handle key press events\n",
    "def on_press(key):\n",
    "    global key_pressed\n",
    "    try:\n",
    "        if key.char == 'w':\n",
    "            key_pressed = '0'  # Straight\n",
    "        elif key.char == 'a':\n",
    "            key_pressed = '1'  # Left\n",
    "        elif key.char == 'd':\n",
    "            key_pressed = '2'  # Right\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "def on_release(key):\n",
    "    global key_pressed\n",
    "    key_pressed = None\n",
    "\n",
    "# Keyboard listener\n",
    "listener = key.Listener(on_press=on_press, on_release=on_release)\n",
    "listener.start()\n",
    "\n",
    "# Function to capture and save screenshots\n",
    "def collect_data():\n",
    "    with mss.mss() as sct:\n",
    "        monitor = sct.monitors[1]  # Screen to capture\n",
    "        \n",
    "        while True:\n",
    "            if key_pressed is not None:\n",
    "                # Take a screenshot\n",
    "                screenshot = np.array(sct.grab(monitor))\n",
    "                \n",
    "                # Convert the image from BGRA to BGR (for OpenCV)\n",
    "                img_bgr = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "                \n",
    "                # Resize the image (optional, you can adjust this)\n",
    "                img_bgr = cv2.resize(img_bgr, (100, 100))\n",
    "                \n",
    "                # Create a unique filename based on the timestamp\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S%f\")\n",
    "                img_filename = f\"{timestamp}.jpg\"\n",
    "                \n",
    "                # Check if key_pressed is not None\n",
    "                if key_pressed is not None:\n",
    "                    # Path to the directory with the correct label\n",
    "                    label_dir = os.path.join(data_dir, key_pressed)\n",
    "                    img_path = os.path.join(label_dir, img_filename)\n",
    "                    \n",
    "                    # Save the original screenshot\n",
    "                    cv2.imwrite(img_path, img_bgr)\n",
    "                    print(f\"Screenshot saved at {img_path}\")\n",
    "\n",
    "                    # If the key is 'left' (1) or 'right' (2), flip the image and save with the opposite label\n",
    "                    if key_pressed == '1':  # Left\n",
    "                        flipped_img = cv2.flip(img_bgr, 1)  # Flip horizontally\n",
    "                        flipped_label_dir = os.path.join(data_dir, '2')  # Flip to right\n",
    "                    elif key_pressed == '2':  # Right\n",
    "                        flipped_img = cv2.flip(img_bgr, 1)  # Flip horizontally\n",
    "                        flipped_label_dir = os.path.join(data_dir, '1')  # Flip to left\n",
    "                    \n",
    "                    if key_pressed in ['1', '2']:  # Save the flipped image\n",
    "                        flipped_img_filename = f\"{timestamp}_flipped.jpg\"\n",
    "                        flipped_img_path = os.path.join(flipped_label_dir, flipped_img_filename)\n",
    "                        cv2.imwrite(flipped_img_path, flipped_img)\n",
    "                        print(f\"Flipped screenshot saved at {flipped_img_path}\")\n",
    "\n",
    "# Start data collection\n",
    "collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 100, 100\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Data augmentation for FastAI\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop((IMG_HEIGHT, IMG_WIDTH), scale=(0.8, 1.0)),\n",
    "])\n",
    "\n",
    "# Dataset class for in-memory data\n",
    "class TrackmaniaDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert image to uint8 type for PIL compatibility\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert to tensor and normalize to [0, 1]\n",
    "        image = np.array(image).astype(np.float32) / 255.0\n",
    "        image = torch.tensor(image).permute(2, 0, 1)  # Convert to CxHxW format\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Function to load data from directory\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label_dir in os.listdir(data_dir):\n",
    "        label_path = os.path.join(data_dir, label_dir)\n",
    "        for img_file in os.listdir(label_path):\n",
    "            img = cv2.imread(os.path.join(label_path, img_file))\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            images.append(img)\n",
    "            labels.append(int(label_dir))  # label 0 for straight, 1 for left, 2 for right, 3 for backward\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_dir = \"trackmania_data\"\n",
    "X, y = load_data(data_dir)\n",
    "X = X / 255.0  # Normalize images\n",
    "\n",
    "# Handle any invalid labels outside expected range\n",
    "if np.any((y < 0) | (y > 3)):\n",
    "    raise ValueError(\"Some labels are outside the expected range 0-3.\")\n",
    "\n",
    "# Balance the data through oversampling\n",
    "oversampled_images = []\n",
    "oversampled_labels = []\n",
    "for image, label in zip(X, y):\n",
    "    if label in [1, 2]:  # Oversample underrepresented classes (left and right)\n",
    "        for _ in range(5):  # Duplicate examples\n",
    "            oversampled_images.append(image)\n",
    "            oversampled_labels.append(label)\n",
    "    else:\n",
    "        oversampled_images.append(image)\n",
    "        oversampled_labels.append(label)\n",
    "\n",
    "X_balanced = np.array(oversampled_images)\n",
    "y_balanced = np.array(oversampled_labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = TrackmaniaDataset(X_train, y_train, transform=transform)\n",
    "test_dataset = TrackmaniaDataset(X_test, y_test, transform=transforms.Resize((IMG_HEIGHT, IMG_WIDTH)))\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Wrap DataLoader with FastAI's DataLoaders\n",
    "dls = DataLoaders(train_loader, test_loader)\n",
    "\n",
    "# CNN Model definition\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 25 * 25, 128)  # Adjust based on your input size\n",
    "        self.fc2 = nn.Linear(128, 4)  # 4 classes: forward, left, right, backward\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = CNNModel()\n",
    "\n",
    "# Create a learner using FastAI's Learner\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), opt_func=Adam, metrics=accuracy)\n",
    "\n",
    "# Train the model\n",
    "learn.fit_one_cycle(EPOCHS, LEARNING_RATE)\n",
    "\n",
    "# Save the trained model\n",
    "learn.save('trackmania_model')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model laden\n",
    "model = CNNModel()\n",
    "model.load_state_dict(torch.load('trackmania_model.pth'))\n",
    "model.eval()  # Zet model in evaluatiemodus\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 100, 100\n",
    "\n",
    "\n",
    "# Functie om screenshots te nemen en te gebruiken voor het model\n",
    "def drive():\n",
    "    with mss.mss() as sct:\n",
    "        monitor = sct.monitors[1]  # Scherm dat je wilt capturen (je kunt dit aanpassen)\n",
    "\n",
    "        while True:\n",
    "            # Screenshot nemen\n",
    "            screenshot = np.array(sct.grab(monitor))\n",
    "\n",
    "            # Converteer de afbeelding van BGRA naar BGR (voor OpenCV)\n",
    "            img_bgr = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "            # Verklein de afbeelding naar 100x100 pixels (zelfde als tijdens training)\n",
    "            img_resized = cv2.resize(img_bgr, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "            # Converteer de afbeelding naar een tensor voor het model\n",
    "            img_tensor = torch.tensor(img_resized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0) / 255.0  # PyTorch input\n",
    "\n",
    "            # Maak een voorspelling\n",
    "            with torch.no_grad():\n",
    "                output = model(img_tensor)\n",
    "                predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "            # Print de voorspelling naar de console\n",
    "            print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "            # Voeg de voorspelling toe aan het frame\n",
    "            cv2.putText(img_bgr, f'Predicted: {predicted_class}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # AZERTY\n",
    "            # if predicted_class == 0:\n",
    "            #     keyboard.press(\"w\")\n",
    "            #     keyboard.release(\"q\")\n",
    "            #     keyboard.release(\"d\")\n",
    "            #     keyboard.release(\"s\")\n",
    "            # elif predicted_class == 1:\n",
    "            #     keyboard.press(\"q\")\n",
    "            #     keyboard.release(\"z\")\n",
    "            #     keyboard.release(\"d\")\n",
    "            #     keyboard.release(\"s\")\n",
    "            # elif predicted_class == 2:\n",
    "            #     keyboard.press(\"d\")\n",
    "            #     keyboard.release(\"q\")\n",
    "            #     keyboard.release(\"z\")\n",
    "            #     keyboard.release(\"s\")\n",
    "            # elif predicted_class == 3:\n",
    "            #     keyboard.press(\"s\")\n",
    "            #     keyboard.release(\"q\")\n",
    "            #     keyboard.release(\"z\")\n",
    "            #     keyboard.release(\"d\")\n",
    "\n",
    "            # QWERTY\n",
    "            if predicted_class == 0:\n",
    "                keyboard.press(\"w\")\n",
    "                keyboard.release(\"a\")\n",
    "                keyboard.release(\"d\")\n",
    "                keyboard.release(\"s\")\n",
    "            elif predicted_class == 1:\n",
    "                keyboard.press(\"a\")\n",
    "                keyboard.release(\"w\")\n",
    "                keyboard.release(\"d\")\n",
    "                keyboard.release(\"s\")\n",
    "            elif predicted_class == 2:\n",
    "                keyboard.press(\"d\")\n",
    "                keyboard.release(\"w\")\n",
    "                keyboard.release(\"a\")\n",
    "                keyboard.release(\"s\")\n",
    "            elif predicted_class == 3:\n",
    "                keyboard.press(\"s\")\n",
    "                keyboard.release(\"w\")\n",
    "                keyboard.release(\"a\")\n",
    "                keyboard.release(\"d\")\n",
    "\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start de drive functie\n",
    "drive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
